{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOG+rVXrjWrrRE+Lb4H7R6k"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["파일 경로는 사용자에 맞추어 수정해야 합니다.\n","\n","현재는 구글 드라이브 내부에 datasets, models, submissions 폴더가 있다고 가정합니다.\n","\n","\n","- datasets: 대회 측에서 제공한 CT 데이터셋이 들어갑니다.\n","\n","- models: 해당 코드를 통해 훈련된 최대 성능의 모델이 저장됩니다.\n","\n","- submissions: 대회에 제출하기 위해 작성한 csv 파일을 저장합니다.\n"],"metadata":{"id":"on-tN4GUeEF-"}},{"cell_type":"code","source":["!git clone https://github.com/rwightman/pytorch-image-models"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qYfLariMd8z_","executionInfo":{"status":"ok","timestamp":1668133020518,"user_tz":-540,"elapsed":2067,"user":{"displayName":"‍차정훈[학생](응용과학대학 우주과학과)","userId":"12973916152823414636"}},"outputId":"e3dcf768-05fd-40a7-eb6e-b5406af703a4"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'pytorch-image-models'...\n","remote: Enumerating objects: 11718, done.\u001b[K\n","remote: Counting objects: 100% (627/627), done.\u001b[K\n","remote: Compressing objects: 100% (229/229), done.\u001b[K\n","remote: Total 11718 (delta 439), reused 525 (delta 387), pack-reused 11091\u001b[K\n","Receiving objects: 100% (11718/11718), 20.83 MiB | 27.35 MiB/s, done.\n","Resolving deltas: 100% (8598/8598), done.\n"]}]},{"cell_type":"code","source":["import shutil\n","\n","shutil.copytree(\"/content/pytorch-image-models/timm\", \"/content/timm\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"aCQKuQgKetBq","executionInfo":{"status":"ok","timestamp":1668133110038,"user_tz":-540,"elapsed":443,"user":{"displayName":"‍차정훈[학생](응용과학대학 우주과학과)","userId":"12973916152823414636"}},"outputId":"1243c148-8689-41f1-b67b-6efc18c241f2"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/timm'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":3}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f89q3aBZd2dL"},"outputs":[],"source":["import os\n","import torch\n","import torch.nn as nn\n","from torch import optim\n","from torchvision import utils\n","import torchvision.transforms as transforms\n","from torch.utils.data import Dataset, DataLoader, random_split\n","import numpy as np\n","import pandas as pd\n","from PIL import Image\n","from timm.models import convnext\n","import random\n","import torch.nn.functional as F\n","import csv\n","import time\n","import skimage, torchvision\n","\n","random_seed=0\n","# torch random 값 생성\n","torch.manual_seed(random_seed)\n","# 현 gpu에서의 random 값 생성 \\ \n","torch.cuda.manual_seed(random_seed)\n","# 2개 이상의 gpu를 사용할 때\n","torch.cuda.manual_seed_all(random_seed)\n","# randomness가 들어간 함수 미사용\n","torch.backends.cudnn.deterministic = True\n","# True일 시, 동일한 사이즈에 텐서들이 들어올때의 속도향상을 불러온다.\n","torch.backends.cudnn.benchmark = False\n","# numpy의 random seed 고정\n","np.random.seed(random_seed)\n","# random 라이브러리의 seed 고정\n","random.seed(random_seed)\n","\n","##########################################################################\n","################################ Training ################################\n","##########################################################################\n","\n","convnext_ = convnext.convnext_femto(pretrained=True)\n","FC_in_features = convnext_.head.fc.in_features\n","convnext_.head.fc = nn.Linear(in_features=FC_in_features, out_features=5)\n","\n","print(convnext_)\n","\n","model = convnext_\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # 학습 환경 설정\n","\n","model.to(device)\n","\n","dir = '/content/datasets/ChestCT/'\n","\n","torchvision_transform = transforms.Compose([\n","    transforms.Resize((300, 300)), \n","    transforms.RandomCrop(288),\n","    transforms.RandomHorizontalFlip(p=0.5),\n","    transforms.RandomVerticalFlip(p=0.5),\n","    transforms.RandomPerspective(distortion_scale=0.5, p=0.5),\n","    transforms.ToTensor()\n","])\n","\n","class TrainDataset(Dataset):\n","    def __init__(self, file_path, transform=torchvision_transform):\n","        df = pd.read_csv(file_path)\n","        self.path = df.iloc[:, 0].values\n","        self.imgs = list(self.path)\n","        self.y = df.iloc[:, 1].values\n","        self.transform = transform\n","\n","    def __getitem__(self, index):\n","        subdir = \"ChestCT_Train/CT_Train_images/\"\n","        img_path = dir + subdir + self.imgs[index]\n","        x = Image.open(img_path).convert(\"RGB\")\n","        y = self.y[index]\n","        if self.transform:\n","            x = self.transform(x)\n","        return x, y\n","\n","    def __len__(self):\n","        return len(self.imgs)\n","    \n","class TestDataset(Dataset):\n","    def __init__(self, file_path, transform=torchvision_transform):\n","        df = pd.read_csv(file_path)\n","        self.path = df.iloc[:, 0].values\n","        self.imgs = list(self.path)\n","        self.y = df.iloc[:, 1].values\n","        self.transform = transform\n","\n","    def __getitem__(self, index):\n","        subdir = \"ChestCT_Test/\"\n","        img_path = dir + subdir + self.imgs[index]\n","        x = Image.open(img_path).convert(\"RGB\")\n","        y = self.y[index]\n","        if self.transform:\n","            x = self.transform(x)\n","        return x, y\n","    \n","    def __len__(self):\n","        return len(self.imgs)\n","    \n","dataset = TrainDataset('/content/datasets/ChestCT/train.csv')\n","dataset_size = len(dataset)\n","train_size = int(dataset_size * 0.8)\n","validation_size = int(dataset_size - train_size)\n","\n","train_dataset, val_dataset = random_split(dataset, [train_size, validation_size])\n","\n","test_dataset = TestDataset('/content/datasets/ChestCT/test.csv')\n","\n","print(f\"Training Data Size : {len(train_dataset)}\")\n","print(f\"Validation Data Size : {len(val_dataset)}\")\n","print(f\"Testing Data Size : {len(test_dataset)}\")\n","\n","train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True, drop_last=True)\n","val_dataloader = DataLoader(val_dataset, batch_size=64, shuffle=True, drop_last=True)\n","test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n","\n","class LabelSmoothLoss(nn.Module):\n","    def __init__(self, smoothing=0.0):\n","        super(LabelSmoothLoss, self).__init__()\n","        self.smoothing = smoothing\n","    \n","    def forward(self, input, target):\n","        log_prob = F.log_softmax(input, dim=-1)\n","        weight = input.new_ones(input.size()) * \\\n","            self.smoothing / (input.size(-1) - 1.)\n","        weight.scatter_(-1, target.unsqueeze(-1), (1. - self.smoothing))\n","        loss = (-weight * log_prob).sum(dim=-1).mean()\n","        return loss\n","\n","lr = 0.0001\n","num_epochs = 30\n","optimizer = optim.Adam(model.parameters(), lr=lr)\n","loss_function = LabelSmoothLoss(0.1).to(device)\n","\n","scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, [15,25],gamma=0.1)\n","\n","params = {\n","    'num_epochs':num_epochs,\n","    'optimizer':optimizer,\n","    'loss_function':loss_function,\n","    'train_dataloader':train_dataloader,\n","    'val_dataloader': val_dataloader,\n","    'device':device\n","}\n","\n","def train(model, params):\n","    loss_function=params[\"loss_function\"]\n","    train_dataloader=params[\"train_dataloader\"]\n","    val_dataloader=params[\"val_dataloader\"]\n","    device=params[\"device\"]\n","    \n","    best_acc = 0\n","    current_acc = 0\n","    test_loss = 0\n","    \n","    for epoch in range(0, num_epochs):\n","      model.train()\n","      start_time = time.time()\n","      for i, data in enumerate(train_dataloader, 0):\n","        # train dataloader 로 불러온 데이터에서 이미지와 라벨을 분리\n","        inputs, labels = data\n","        inputs = inputs.to(device)\n","        labels = labels.to(device)\n","\n","        # 이전 batch에서 계산된 가중치를 초기화\n","        optimizer.zero_grad() \n","\n","        # forward + back propagation 연산\n","        outputs = model(inputs)\n","\n","        train_loss = loss_function(outputs, labels)\n","\n","        train_loss.backward()\n","        optimizer.step()\n","      scheduler.step()\n","\n","      # test accuracy 계산\n","      model.eval()\n","      total = 0\n","      correct = 0\n","      accuracy = []\n","      with torch.inference_mode():\n","        for i, data in enumerate(val_dataloader, 0):\n","            inputs, labels = data\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","\n","            # 결과값 연산\n","            outputs = model(inputs)\n","\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","            test_loss = loss_function(outputs, labels).item()\n","            current_acc = 100 * correct/total\n","            accuracy.append(100 * correct/total)\n","        \n","      if current_acc > best_acc:\n","        best_acc = current_acc\n","        torch.save(model.state_dict(), \"/content/models/convnext_femto.pt\")\n","        print(best_acc, \" ‧₊˚.⋆·ฺ.∗̥✩⁺˚ ੈ‧˚૮꒰˵• ﻌ •˵꒱აੈ✩‧₊˚ੈ*:ﾟ*｡.⋆·ฺᐝ.∗̥⁺˚ Let's save the BEST MODEL!\")\n","\n","      torch.save(model.state_dict(), \"/content/models/convnext_femto.pt\")\n","\n","      # 학습 결과 출력\n","      print('Epoch: %d/%d, Train loss: %.6f, Val loss: %.6f, Accuracy: %.2f' %(epoch+1, num_epochs, train_loss.item(), test_loss, 100*correct/total))\n","      print(\"Time: {:.4f}sec\".format((time.time() - start_time)))\n","      \n","train(model, params)"]},{"cell_type":"code","source":["###########################################################################\n","################################ Inference ################################\n","###########################################################################\n","\n","# 경로 지정\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # 학습 환경 설정\n","\n","model2use = convnext.convnext_femto(pretrained=True)\n","FC_in_features = model2use.head.fc.in_features\n","model2use.head.fc = nn.Linear(in_features=FC_in_features, out_features=5)\n","\n","model2use.load_state_dict(torch.load(\"/content/models/convnext_femto.pt\"))\n","model2use.to(device)\n","\n","\n","def inference(img_path):\n","    global model2use\n","    img = Image.open(img_path).convert(\"RGB\")\n","    img = torchvision_transform2(img)\n","    img = img.to(device)\n","    outputs = model2use(img[None, ...]) # or model.features(img[None,...]) \n","    # print(outputs)\n","    return outputs\n","\n","torchvision_transform2 = transforms.Compose([\n","    transforms.Resize((288, 288)), \n","    transforms.ToTensor()\n","])\n","\n","submission = open('/content/submissions/' + 'convnext_femto.csv', 'w')\n","wr = csv.writer(submission)\n","wr.writerow([\"filename\", \"result\"])\n","\n","test_list = sorted(os.listdir('/content/datasets/ChestCT/ChestCT_Test'))\n","i = 0\n","for img_path in test_list:\n","    i += 1\n","    print(i)\n","    with torch.no_grad():\n","        model2use.eval()\n","        output = inference(os.path.join('/content/datasets/ChestCT/ChestCT_Test/',img_path))\n","        predict = int(output.argmax())\n","        print(predict)\n","        \n","        wr.writerow([img_path, predict])"],"metadata":{"id":"ixuuNDCvd6IL"},"execution_count":null,"outputs":[]}]}